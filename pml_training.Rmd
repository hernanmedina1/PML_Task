---
title: "PML Training"
author: "Hernan L. Medina"
date: "December 11, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## PML Training

This exercise uses data and findings from Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. "Qualitative Activity Recognition of Weight Lifting Exercises."" Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13). Stuttgart, Germany: ACM SIGCHI, 2013. The paper can be found here <http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf>. The data are licensed under the  Creative Commons license (CC BY-SA). The question addressed is whether or not a model can be trained to detect when a person is performing an exercise correctly or incorrectly. Five categories were defined as follows:

- A = exercise performed exactly as specified
- B = throwing the elbows to the front 
- C = lifting the dumbbell only halfway
- D = lowering the dumbbell only halfway
- E = throwing the hips to the front 

## Read Training Data

The following code chunk loads the packages used in this analysis, and reads the data. The file had row names with a blank column name. The read_csv function give a warning and names it X1. Additionally, messages show some variables such as (x, y, z) components were read as integer. These will be converted to numeric prior to calculating features such as skewness and kurtosis. Warnings and messages have been omitted in this document, for brevity.

```{r get_training_data, cache=TRUE, warning=FALSE, message=FALSE}
library(readr)
library(dplyr)
library(caret)
library(randomForest)
library(e1071)
pmltrain <- read_csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
         ,na = c("NA","","#DIV/0!"), guess_max = 10000)
```

## Explore Training Data and Calculate Features

The original data set contained about one hundred variables that were largely missing. These were calculations such as minimum, maximum, variance, skewness and kurtosis of the variables captured by the devices on the belt, arm, forearm and dumbbell sensors. The following code chunk shows the dimensions of the original data set, determines which variables had missing values, creates a training data set containing only variables completely filled, shows the dimensions of the training data, converts variables read as integer to numeric, calculates features for modeling, and plots some variables to examine their relationship with the response variable. code and results other than plots have been hidden for brevity.

```{r explore, cache=TRUE, echo=FALSE, results='hide'}
dim(pmltrain)
sum(complete.cases(pmltrain))
na_count <-sapply(pmltrain, function(y) { sum(is.na(y)) } )
table(na_count)
good_var <- na_count == 0
print('variables completely filled'); names(pmltrain[good_var])
print('variables largely missing'); names(pmltrain[,!good_var])
training <- pmltrain[,good_var]
dim(training)
#
# Fix numeric variables read as integer
#
training$accel_arm_x <- as.numeric(training$accel_arm_x)
training$accel_arm_y <- as.numeric(training$accel_arm_y)
training$accel_arm_z <- as.numeric(training$accel_arm_z)
training$accel_belt_x <- as.numeric(training$accel_belt_x)
training$accel_belt_y <- as.numeric(training$accel_belt_y)
training$accel_belt_z <- as.numeric(training$accel_belt_z)
training$accel_dumbbell_x <- as.numeric(training$accel_dumbbell_x)
training$accel_dumbbell_y <- as.numeric(training$accel_dumbbell_y)
training$accel_dumbbell_z <- as.numeric(training$accel_dumbbell_z)
training$accel_forearm_x <- as.numeric(training$accel_forearm_x)
training$accel_forearm_y <- as.numeric(training$accel_forearm_y)
training$accel_forearm_z <- as.numeric(training$accel_forearm_z)
training$magnet_arm_x <- as.numeric(training$magnet_arm_x)
training$magnet_arm_y <- as.numeric(training$magnet_arm_y)
training$magnet_arm_z <- as.numeric(training$magnet_arm_z)
training$magnet_belt_x <- as.numeric(training$magnet_belt_x)
training$magnet_belt_y <- as.numeric(training$magnet_belt_y)
training$magnet_belt_z <- as.numeric(training$magnet_belt_z)
training$magnet_dumbbell_x <- as.numeric(training$magnet_dumbbell_x)
training$magnet_dumbbell_y <- as.numeric(training$magnet_dumbbell_y)
training$magnet_forearm_x <- as.numeric(training$magnet_forearm_x)
training$total_accel_arm <- as.numeric(training$total_accel_arm)
training$total_accel_belt <- as.numeric(training$total_accel_belt)
training$total_accel_dumbbell <- as.numeric(training$total_accel_dumbbell)
training$total_accel_forearm <- as.numeric(training$total_accel_forearm)
#
# create features
#
training$gyros_belt <- with(training, sqrt(gyros_belt_x^2 + gyros_belt_y^2 + gyros_belt_z^2))
training$accel_belt <- with(training, sqrt(accel_belt_x^2 + accel_belt_y^2 + accel_belt_z^2))
training$magnet_belt <- with(training, sqrt(magnet_belt_x^2 + magnet_belt_y^2 + magnet_belt_z^2))
training$gyros_arm <- with(training, sqrt(gyros_arm_x^2 + gyros_arm_y^2 + gyros_arm_z^2))
training$accel_arm <- with(training, sqrt(accel_arm_x^2 + accel_arm_y^2 + accel_arm_z^2))
training$magnet_arm <- with(training, sqrt(magnet_arm_x^2 + magnet_arm_y^2 + magnet_arm_z^2))
training$gyros_dumbbell <- with(training, sqrt(gyros_dumbbell_x^2 + gyros_dumbbell_y^2 + gyros_dumbbell_z^2))
training$accel_dumbbell <- with(training, sqrt(accel_dumbbell_x^2 + accel_dumbbell_y^2 + accel_dumbbell_z^2))
training$magnet_dumbbell <- with(training, sqrt(magnet_dumbbell_x^2 + magnet_dumbbell_y^2 + magnet_dumbbell_z^2))
training$gyros_forearm <- with(training, sqrt(gyros_forearm_x^2 + gyros_forearm_y^2 + gyros_forearm_z^2))
training$accel_forearm <- with(training, sqrt(accel_forearm_x^2 + accel_forearm_y^2 + accel_forearm_z^2))
training$magnet_forearm <- with(training, sqrt(magnet_forearm_x^2 + magnet_forearm_y^2 + magnet_forearm_z^2))
training$classe <- as.factor(training$classe)
#
# check for and eliminate rows with missing values
#
cc <- complete.cases(training)
sum(cc)
training <- training[cc,]
#
# select variables for grouped calculations
#
training <- select(training, -X1, -raw_timestamp_part_1, -raw_timestamp_part_2,
                 -cvtd_timestamp, -user_name, -new_window)
by_window <- group_by(select(training, -classe), num_window)
t <- summarize_all(by_window, c('min', 'max', 'sum', 'mean', 'sd', 'var', 'skewness', 'kurtosis'))
t$accel_belt_range <- t$accel_belt_max - t$accel_belt_min
t$accel_arm_range <- t$accel_arm_max - t$accel_arm_min
t$accel_forearm_range <- t$accel_forearm_max - t$accel_forearm_min
t$accel_dumbbell_range <- t$accel_dumbbell_max - t$accel_dumbbell_min
t$gyros_belt_range <- t$gyros_belt_max - t$gyros_belt_min
t$gyros_arm_range <- t$gyros_arm_max - t$gyros_arm_min
t$gyros_forearm_range <- t$gyros_forearm_max - t$gyros_forearm_min
t$gyros_dumbbell_range <- t$gyros_dumbbell_max - t$gyros_dumbbell_min
t$magnet_belt_range <- t$magnet_belt_max - t$magnet_belt_min
t$magnet_arm_range <- t$magnet_arm_max - t$magnet_arm_min
t$magnet_forearm_range <- t$magnet_forearm_max - t$magnet_forearm_min
t$magnet_dumbbell_range <- t$magnet_dumbbell_max - t$magnet_dumbbell_min
sum(complete.cases(t))
na_t <-sapply(t, function(y) { sum(is.na(y)) } )
bad_var <- na_t > 2
t <- t[ , !bad_var]
good_t <- complete.cases(t)
t <- t[ good_t, ]
training <- inner_join(select(training, num_window, classe), t, by='num_window')
```
```{r plot, cache=TRUE, echo=FALSE}
#
# Plot some variables 
#
par(mfrow=c(2,3))
with(training, boxplot(accel_belt_max ~ classe, range=1.5, main='Acceleration Belt Maximum'))
with(training, boxplot(yaw_belt_mean ~ classe, range=1.5, main='Yaw Belt Mean'))
with(training, boxplot(accel_arm_x_skewness ~ classe, range=1.5, main='Acceleration Arm X Skewness'))
with(training, boxplot(accel_forearm_y_min ~ classe, range=1.5, main='Acceleration Forearm Y Minimum'))
with(training, boxplot(gyros_dumbbell_y_min ~ classe, range=1.5, main='Gyroscope Dumbbell Y Minimum'))
with(training, boxplot(accel_forearm_var ~ classe, range=1.5, main='Acceleration Forearm Variance'))
```

## Search An Efficient Number of Predictors

The following code chunk uses random forest cross validation to determine the error rate for different numbers of predictors. The cross validation is done with only 3 folds and with a maximum of 30 trees in order to reduce the time it takes for the code to run. Normally I would use 10=fold cross-validation and a maximum of 100 trees. The results show that 14 variables produce optimal results.

```{r rfcrossval, cache=TRUE}
set.seed(819)
predictors <- dplyr::select(training, -classe, -num_window)
response <- training$classe
m1 <- rfcv(predictors, response, cv.fold=3, ntree=30)
m1$n.var; round(m1$error.cv, digits=7)
```

## Determine the most important predictors

The following code chunk uses the caret package to perform random forest with cross validation to determine the most important predictors. The first section determines importance using all the predictors, using verbose iteration to be able to track progress. The next step selects the 14 most important predictors based on Mean Decrease Accuracy of the final model. Finally, I refit the random forest using only those 14 predictors.

```{r rforest_imp, cache=TRUE, message=FALSE}
set.seed(819)
predictors <- dplyr::select(training, -classe, -num_window)
response <- training$classe
tc <- trainControl(method = "cv", number=3, verboseIter=TRUE, savePredictions = 'final')
m2 <- train(predictors, response, method='rf', trControl=tc, ntree=30, importance=TRUE)
summary(m2)
confusionMatrix(m2)
varImpPlot(m2$finalModel)
im2 <- data.frame(importance(m2$finalModel))
ndx <- im2$MeanDecreaseAccuracy > 3.85
imp_names <- row.names(im2[ndx,])
predictors <- training[, imp_names]
set.seed(819)
tc <- trainControl(method = "cv", number=3, verboseIter=TRUE, savePredictions = 'final')
m3 <- train(predictors, response, method='rf', trControl=tc, ntree=30, importance=TRUE)
summary(m3)
confusionMatrix(m3)
varImpPlot(m3$finalModel)
```

## Predict Results for Testing Data

I expected the testing data to consists of windows of measurements, such as the training data. Given windows of 25 to 35 observations, I would have calculated all the features for the testing data, such as min, max, variance, skewness and kurtosis of the observed variables and calculated magnitudes of variables. Instead, it consisted of only twenty observations. Further examination showed that the user name and window number corresponded to rows in the training data. Thus the test consisted of whether or not the model accurately predicted some of the rows in the same data that was used to train it. The test was 100% successful, but this is an optimistic assessment. Additional data, not used to fit the model, would be needed to make an honest assessment.

```{r testing, cache=TRUE, warning=FALSE, message=FALSE}
pmltest <- read_csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
                     ,na = c("NA","","#DIV/0!"))
testing <- inner_join(select(pmltest, num_window, problem_id), t, by='num_window')
predictors <- data.frame(testing[, imp_names], testing$problem_id)
predicted <- predict(m3, newdata=predictors)
answers <- data.frame(testing$problem_id, predicted)
```
